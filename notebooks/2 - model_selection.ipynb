{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Train-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../data/processed/'\n",
    "X_train = pd.read_csv(dirname + 'X_train_trimmed.csv', sep=',')\n",
    "X_test = pd.read_csv(dirname + 'X_test_trimmed.csv', sep=',')\n",
    "y_train = pd.read_csv(dirname + 'y_train_trimmed.csv', sep=',')\n",
    "y_test = pd.read_csv(dirname + 'y_test_trimmed.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions (Delete Later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRETCH**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from utils import print_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a scaler to the feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the k best features. To begin with, there are 50 features. However, many have low correlations with the target and can safely be dropped, leading to simpler models. Some trial and error indicates that k=8 is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb = SelectKBest(f_classif, k=8)\n",
    "\n",
    "X_train_sc_skb = skb.fit_transform(\n",
    "    X_train_sc, \n",
    "    np.ravel(y_train.to_numpy())\n",
    ")\n",
    "\n",
    "X_test_sc_skb = skb.transform(X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate polynomial features. Some trial and error seems to indicate that there is no reason to include polynomial features here; hence, we've left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=1)\n",
    "\n",
    "X_train_sc_skb_poly = poly.fit_transform(X_train_sc_skb)\n",
    "X_test_sc_skb_poly = poly.transform(X_test_sc_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(\n",
    "    train: [np.array, np.array],\n",
    "    test: [np.array, np.array],\n",
    "    regressor\n",
    "):\n",
    "    \"\"\"\n",
    "    Return a fitted regressor.\n",
    "\n",
    "    Fit the regressor and print out a variety of test score.\n",
    "\n",
    "    :param train: [X_train, y_train]\n",
    "    :param test: [X_test, y_train]\n",
    "    :param regressor: a regression model instance such as LinearRegression()\n",
    "\n",
    "    :return: A fitted regression model\n",
    "    \"\"\"\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = regressor.predict(X_train)\n",
    "    y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "    print_scores(\n",
    "        [X_train, y_train, y_train_pred], \n",
    "        [X_test, y_test, y_test_pred]\n",
    "    )\n",
    "\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train: 89254.29011925084\n",
      "RMSE test: 86076.32198255186\n",
      "MAE train: 61171.33790170132\n",
      "MAE test: 61005.00779588944\n",
      "R**2 train: 0.7656159664874821\n",
      "R**2 test: 0.7842687280366942\n",
      "Adj R**2 train: 0.7651163321195018\n",
      "Adj R**2 test: 0.7828828740412126\n"
     ]
    }
   ],
   "source": [
    "model = run_regression(\n",
    "    [X_train_sc_skb_poly, y_train],\n",
    "    [X_test_sc_skb_poly, y_test],\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. features: 9\n",
      "Coefficients: [[ 0.00000000e+00  2.07690707e+05  8.51663351e+04 -5.82135617e+04\n",
      "  -8.79517087e+04 -4.19336571e+18 -4.19336571e+18 -4.19336571e+18\n",
      "   7.25821433e+05]]\n"
     ]
    }
   ],
   "source": [
    "print(f'No. features: {model.n_features_in_}')\n",
    "print(f'Coefficients: {model.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train: 89677.89496762241\n",
      "RMSE test: 86991.59909339725\n",
      "MAE train: 61978.9517333725\n",
      "MAE test: 62135.71752462699\n",
      "R**2 train: 0.7633858928127033\n",
      "R**2 test: 0.7796564563685622\n",
      "Adj R**2 train: 0.7628815046164252\n",
      "Adj R**2 test: 0.7782409732188955\n"
     ]
    }
   ],
   "source": [
    "model = run_regression(\n",
    "    [X_train_sc_skb_poly, y_train],\n",
    "    [X_test_sc_skb_poly, y_test],\n",
    "    Ridge(alpha=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train: 89251.61748105274\n",
      "RMSE test: 86063.53998478205\n",
      "MAE train: 61212.58438737709\n",
      "MAE test: 61045.37161907897\n",
      "R**2 train: 0.7656300031089445\n",
      "R**2 test: 0.7843327937829144\n",
      "Adj R**2 train: 0.7651303986627058\n",
      "Adj R**2 test: 0.7829473513446891\n"
     ]
    }
   ],
   "source": [
    "model = run_regression(\n",
    "    [X_train_sc_skb_poly, y_train],\n",
    "    [X_test_sc_skb_poly, y_test],\n",
    "    Lasso(alpha=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. features: 9\n",
      "Coefficients: [     0.         208684.28911058  85469.11127912 -57334.05184123\n",
      " -88799.75199856  -1001.1963041   14137.77705301     -0.\n",
      " 725819.13662042]\n"
     ]
    }
   ],
   "source": [
    "print(f'No. features: {model.n_features_in_}')\n",
    "print(f'Coefficients: {model.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
